{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GLGKDq-OgH_o"
      },
      "source": [
        "# Lab1 - Scikit-learn\n",
        "Author: *Jean-Charl Pretorius*\n",
        "\n",
        "## 1. Introduction\n",
        "\n",
        "The goal of this lab is to become familiar with the scikit-learn library.\n",
        "\n",
        "You will practice loading example datasets, perform classification and regression with linear scikit-learn models, and investigate the effects of reducing the number of features (columns in X) and the number of samples (rows in X and y).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "PUq5ASAxgH_q"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a_KEYQmdgH_s"
      },
      "source": [
        "## 2. Classification\n",
        "\n",
        "Using yellowbrick spam - classification  \n",
        "https://www.scikit-yb.org/en/latest/api/datasets/spam.html\n",
        "\n",
        "The goal is to investigate `LogisticRegression(max_iter=2000)` and effects of reducing the number of features and number of samples on classification performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zEDyWgbYgH_s"
      },
      "source": [
        "### 2.1 Implement convenience function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "0MFsZ30ggH_s"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def get_classifier_accuracy(model, X, y):\n",
        "    '''Calculate train and validation accuracy of classifier (model)\n",
        "        \n",
        "        Splits feature matrix X and target vector y \n",
        "        with sklearn train_test_split() and random_state=956.\n",
        "        \n",
        "        model (sklearn classifier): Classifier to train and evaluate\n",
        "        X (numpy.array or pandas.DataFrame): Feature matrix\n",
        "        y (numpy.array or pandas.Series): Target vector\n",
        "        \n",
        "        returns: training accuracy, validation accuracy\n",
        "    \n",
        "    '''\n",
        "    # split feature matrix and target vector\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=956)\n",
        "    \n",
        "    # fit model\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # calculate training accuracy\n",
        "    y_train_pred = model.predict(X_train)\n",
        "    training_accuracy = accuracy_score(y_train, y_train_pred)\n",
        "\n",
        "    # calculate validation accuracy\n",
        "    y_test_pred = model.predict(X_test)\n",
        "    validation_accuracy = accuracy_score(y_test, y_test_pred)\n",
        "\n",
        "    return training_accuracy, validation_accuracy\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wetgxYCzgH_t"
      },
      "source": [
        "### 2.2 Load data\n",
        "\n",
        "Use the yellowbrick function `load_spam()`, load the spam data set into feature matrix `X` and target vector `y`.\n",
        "\n",
        "Print size and type of `X` and `y`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "M3ccn70fgH_t",
        "outputId": "9b507b9b-0a86-40d8-bf53-317da71fd3b6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X.size: (4600, 57)\n",
            "type(X): <class 'pandas.core.frame.DataFrame'>\n",
            "y.size: (4600,)\n",
            "type(y): <class 'pandas.core.series.Series'>\n"
          ]
        }
      ],
      "source": [
        "from yellowbrick.datasets import load_spam\n",
        "X, y = load_spam()\n",
        "print(\"X.size: {}\".format(X.shape))\n",
        "print(\"type(X): {}\".format(type(X)))\n",
        "\n",
        "print(\"y.size: {}\".format(y.shape))\n",
        "print(\"type(y): {}\".format(type(y)))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dn2TwRnpgH_u"
      },
      "source": [
        "Using the sklearn function `train_test_split()` prepare a feature matrix `X_small` and target vector `y_small` that contain only **1%** of the rows. Use `random_state=174`.\n",
        "\n",
        "Print size and type of `X_small` and `y_small`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "14SiRQOegH_v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8fc878eb-5d32-436e-d7b4-7b214c186317"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "size of X_small: (46, 57)\n",
            "type of X_small: <class 'pandas.core.frame.DataFrame'>\n",
            "size of y_small: (46,)\n",
            "type of y_small: <class 'pandas.core.series.Series'>\n"
          ]
        }
      ],
      "source": [
        "X_small, X_test, y_small, y_test = train_test_split(X, y, train_size=0.01, random_state=174)\n",
        "print(\"size of X_small:\", X_small.shape)\n",
        "print(\"type of X_small:\", type(X_small))\n",
        "print(\"size of y_small:\", y_small.shape)\n",
        "print(\"type of y_small:\", type(y_small))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B6Ugxn8YgH_w"
      },
      "source": [
        "### 2.3 Train and evaluate models\n",
        "\n",
        "1. Import `LogisticRegression` from sklearn\n",
        "2. Instantiate model `LogisticRegression(max_iter=2000)`.\n",
        "3. Create a pandas DataFrame `results` with columns: Data size, training accuracy, validation accuracy\n",
        "4. Call your convenience function `get_classifier_accuracy()` using \n",
        "    - `X` and `y`\n",
        "    - Only first two columns of `X` and `y`\n",
        "    - `X_small` and `y_small`\n",
        "5. Add the data size, training and validation accuracy for each call to the `results` DataFrame\n",
        "6. Print `results`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "HJg8Y5O_gH_x",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "outputId": "a9dc6994-4636-481b-a328-4ccb15125cff"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                             Data size  training accuracy  \\\n",
              "Data                                                        \n",
              "X and y                     (4600, 57)           0.934493   \n",
              "first 2 columns of X and y   (4600, 2)           0.608986   \n",
              "X_small and y_small           (46, 57)           0.941176   \n",
              "\n",
              "                            validation accuracy  \\\n",
              "Data                                              \n",
              "X and y                                0.918261   \n",
              "first 2 columns of X and y             0.613043   \n",
              "X_small and y_small                    0.750000   \n",
              "\n",
              "                            training - validation accuracy  \n",
              "Data                                                        \n",
              "X and y                                           0.016232  \n",
              "first 2 columns of X and y                       -0.004058  \n",
              "X_small and y_small                               0.191176  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3305d3df-36fe-4d9a-b7d8-de599d52cf3e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Data size</th>\n",
              "      <th>training accuracy</th>\n",
              "      <th>validation accuracy</th>\n",
              "      <th>training - validation accuracy</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Data</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>X and y</th>\n",
              "      <td>(4600, 57)</td>\n",
              "      <td>0.934493</td>\n",
              "      <td>0.918261</td>\n",
              "      <td>0.016232</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>first 2 columns of X and y</th>\n",
              "      <td>(4600, 2)</td>\n",
              "      <td>0.608986</td>\n",
              "      <td>0.613043</td>\n",
              "      <td>-0.004058</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>X_small and y_small</th>\n",
              "      <td>(46, 57)</td>\n",
              "      <td>0.941176</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.191176</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3305d3df-36fe-4d9a-b7d8-de599d52cf3e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3305d3df-36fe-4d9a-b7d8-de599d52cf3e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3305d3df-36fe-4d9a-b7d8-de599d52cf3e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "# 1)\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "# 2) \n",
        "lr = LogisticRegression(max_iter=2000)\n",
        "# 3)\n",
        "results = pd.DataFrame(columns=[\"Data size\", \"training accuracy\", \"validation accuracy\", \"Data\"])\n",
        "\n",
        "# 4 & 5)\n",
        "samples = {\"X and y\":(X, y), \"first 2 columns of X and y\":(X.iloc[:,:2], y), \"X_small and y_small\":(X_small, y_small)}\n",
        "\n",
        "for  name, sample in samples.items():\n",
        "  featureMatrix, targetVector = sample\n",
        "  training_accuracy, validation_accuracy = get_classifier_accuracy(lr, featureMatrix, targetVector)\n",
        "  results = results.append({\"Data size\": featureMatrix.shape, \"training accuracy\": training_accuracy, \"validation accuracy\":  validation_accuracy, \"Data\":name}, ignore_index=True)\n",
        "\n",
        "\n",
        "results[\"training - validation accuracy\"] = results[\"training accuracy\"] - results[\"validation accuracy\"]\n",
        "results.set_index(\"Data\", inplace = True)\n",
        "results\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QxAL1LYpgH_x"
      },
      "source": [
        "### 2.4 Questions\n",
        "1. What is the validation accuracy using all data? What is the difference between training and validation accuracy?\n",
        "1. How does the validation accuracy and difference between training and validation change when only two columns are used? Provide values.\n",
        "1. How does the validation accuracy and difference between training and validation change when only 1% of the rows are used? Provide values.\n",
        "\n",
        "*YOUR ANSWERS HERE*\n",
        "\n",
        "1) \n",
        "\n",
        "- The validation accuracy using all the data is 0.918 and the training accuracy is 0.934.\n",
        "\n",
        "- There is a small diffirence of 0.016 between the validation and training accuracy scores, with validation score being slightly less than training score. Both values are close to 1, which is a good accuracy.\n",
        "\n",
        "2) \n",
        "- When we only use the first two columns the validation accuracy has dropped by 0.305 down to 0.613 and the training accuracy is 0.609. \n",
        "\n",
        "- Both accuracy values have dropped considerably and we also notice that the validation score is actually very slightly higher than the training score by 0.004. The training and validation accuracy is closer than when using all of the data.\n",
        "\n",
        "3)\n",
        "- When we only use 1% of the data the validation accuracy has dropped by 0.168 down to 0.750. The training accuracy is still high at 0.941.\n",
        "\n",
        "- The difference between training and validation accuracy has increased to 0.191\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "otUePQ7UgH_y"
      },
      "source": [
        "## 3. Regression\n",
        "\n",
        "Using yellowbrick energy - regression  \n",
        "https://www.scikit-yb.org/en/latest/api/datasets/energy.html\n",
        "\n",
        "The goal is to investigate `LinearRegression()` and effects of reducing the number of features and number of samples on regression performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HEzhkrObgH_y"
      },
      "source": [
        "### 3.1 Implement convenience function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "Ae4cAzi1gH_z"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def get_regressor_mse(model, X, y):\n",
        "    '''Calculate train and validation mean-squared error (mse) of regressor (model)\n",
        "        \n",
        "        Splits feature matrix X and target vector y \n",
        "        with sklearn train_test_split() and random_state=956.\n",
        "        \n",
        "        model (sklearn regressor): Regressor to train and evaluate\n",
        "        X (numpy.array or pandas.DataFrame): Feature matrix\n",
        "        y (numpy.array or pandas.Series): Target vector\n",
        "        \n",
        "        returns: training mse, validation mse\n",
        "    \n",
        "    '''\n",
        "   \n",
        "    # split feature matrix and target vector\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=956)\n",
        "    \n",
        "    # fit model\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # calculate training mse\n",
        "    y_train_pred = model.predict(X_train)\n",
        "    training_mse = mean_squared_error(y_train, y_train_pred)\n",
        "\n",
        "    # calculate validation mse\n",
        "    y_test_pred = model.predict(X_test)\n",
        "    validation_mse = mean_squared_error(y_test, y_test_pred)\n",
        "    \n",
        "    return training_mse, validation_mse\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kj9n-dL7gH_z"
      },
      "source": [
        "### 3.2 Load data\n",
        "\n",
        "Use the yellowbrick function `load_energy()` load the energy data set into feature matrix `X` and target vector `y`.\n",
        "\n",
        "Print dimensions and type of `X` and `y`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "RvtpvM7DgH_0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78dc6f23-98b3-4bfc-bbe9-ba70323d167e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X.size: (768, 8)\n",
            "type(X): <class 'pandas.core.frame.DataFrame'>\n",
            "y.size: (768,)\n",
            "type(y): <class 'pandas.core.series.Series'>\n"
          ]
        }
      ],
      "source": [
        "from yellowbrick.datasets import load_energy\n",
        "X, y = load_energy()\n",
        "print(\"X.size: {}\".format(X.shape))\n",
        "print(\"type(X): {}\".format(type(X)))\n",
        "\n",
        "print(\"y.size: {}\".format(y.shape))\n",
        "print(\"type(y): {}\".format(type(y)))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LR_S7DskgH_0"
      },
      "source": [
        "Using the sklearn function `train_test_split()` prepare a feature matrix `X_small` and target vector `y_small` that contain only **1%** of the rows. Use `random_state=174`.\n",
        "\n",
        "Print size and type of `X_small` and `y_small`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "F2ZaFU5EgH_0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a30e0600-a5f7-4616-e69b-a90f97193819"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "size of X_small: (7, 8)\n",
            "type of X_small: <class 'pandas.core.frame.DataFrame'>\n",
            "size of y_small: (7,)\n",
            "type of y_small: <class 'pandas.core.series.Series'>\n"
          ]
        }
      ],
      "source": [
        "X_small, X_test, y_small, y_test = train_test_split(X, y, train_size=0.01, random_state=174)\n",
        "print(\"size of X_small:\", X_small.shape)\n",
        "print(\"type of X_small:\", type(X_small))\n",
        "print(\"size of y_small:\", y_small.shape)\n",
        "print(\"type of y_small:\", type(y_small))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uW5FkVOagH_1"
      },
      "source": [
        "### 3.3 Train and evaluate models\n",
        "\n",
        "1. Import `LinearRegression` from sklearn\n",
        "2. Instantiate model `LinearRegression()`.\n",
        "3. Create a pandas DataFrame `results` with columns: Data size, training MSE, validation MSE\n",
        "4. Call your convenience function `get_regressor_mse()` using \n",
        "    - `X` and `y`\n",
        "    - Only first two columns of `X` and `y`\n",
        "    - `X_small` and `y_small`\n",
        "5. Add the data size, training and validation MSE for each call to the `results` DataFrame\n",
        "6. Print `results`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "SeOcJKD8gH_1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "outputId": "4462b029-7147-4fab-fad2-105413f1918a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                           Data size  training MSE  validation MSE  \\\n",
              "Data                                                                 \n",
              "X and y                     (768, 8)  8.012691e+00       10.366349   \n",
              "first 2 columns of X and y  (768, 2)  5.360043e+01       46.410426   \n",
              "X_small and y_small           (7, 8)  2.145702e-29       69.977449   \n",
              "\n",
              "                            training - validation MSE  \n",
              "Data                                                   \n",
              "X and y                                     -2.353657  \n",
              "first 2 columns of X and y                   7.190004  \n",
              "X_small and y_small                        -69.977449  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-75cf18d3-8487-4e37-8a77-c8f22aec41a8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Data size</th>\n",
              "      <th>training MSE</th>\n",
              "      <th>validation MSE</th>\n",
              "      <th>training - validation MSE</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Data</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>X and y</th>\n",
              "      <td>(768, 8)</td>\n",
              "      <td>8.012691e+00</td>\n",
              "      <td>10.366349</td>\n",
              "      <td>-2.353657</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>first 2 columns of X and y</th>\n",
              "      <td>(768, 2)</td>\n",
              "      <td>5.360043e+01</td>\n",
              "      <td>46.410426</td>\n",
              "      <td>7.190004</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>X_small and y_small</th>\n",
              "      <td>(7, 8)</td>\n",
              "      <td>2.145702e-29</td>\n",
              "      <td>69.977449</td>\n",
              "      <td>-69.977449</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-75cf18d3-8487-4e37-8a77-c8f22aec41a8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-75cf18d3-8487-4e37-8a77-c8f22aec41a8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-75cf18d3-8487-4e37-8a77-c8f22aec41a8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "# 1)\n",
        "from sklearn.linear_model import LinearRegression\n",
        "# 2) \n",
        "lr = LinearRegression()\n",
        "# 3)\n",
        "results = pd.DataFrame(columns=[\"Data size\", \"training MSE\", \"validation MSE\", \"Data\"])\n",
        "\n",
        "# 4 & 5)\n",
        "# samples = [(X, y), (X.iloc[:,:2], y), (X_small, y_small)]\n",
        "samples = {\"X and y\":(X, y), \"first 2 columns of X and y\":(X.iloc[:,:2], y), \"X_small and y_small\":(X_small, y_small)}\n",
        "\n",
        "for  name, sample in samples.items():\n",
        "  featureMatrix, targetVector = sample\n",
        "  training_mse, validation_mse = get_regressor_mse(lr, featureMatrix, targetVector)\n",
        "  results = results.append({\"Data size\": featureMatrix.shape, \"training MSE\": training_mse, \"validation MSE\": validation_mse, \"Data\":name}, ignore_index=True)\n",
        "\n",
        "results[\"training - validation MSE\"] = results[\"training MSE\"] - results[\"validation MSE\"]\n",
        "\n",
        "results.set_index(\"Data\", inplace = True)\n",
        "results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tN7-US-VgH_1"
      },
      "source": [
        "### 3.4 Questions\n",
        "1. What is the validation MSE using all data? What is the difference between training and validation MSE?\n",
        "1. How does the validation MSE and difference between training and validation change when only two columns are used? Provide values.\n",
        "1. How does the validation MSE and difference between training and validation change when only 1% of the rows are used? Provide values.\n",
        "\n",
        "*YOUR ANSWERS HERE*\n",
        "\n",
        "1) \n",
        "- The validation MSE using all data is 10.36 and training MSE is 8.01\n",
        "\n",
        "- The difference between training and validation MSE is 2.35\n",
        "\n",
        "2) \n",
        "- The validation MSE using only the first two columns is 46.41. This is an increase of 36.05 compared to using all the data.\n",
        "\n",
        "- The difference between training and validation MSE is 7.19. This is an increase of 4.84 compared to the training and validation MSE difference of the full dataset\n",
        "\n",
        "\n",
        "3) \n",
        "- The validation MSE using 1% is 69.98. This is an increase of 59.62 compared to using all the data.\n",
        "\n",
        "- The difference between training and validation MSE is 69.98. This is an increase of 67.63 compared to the training and validation MSE difference of the full dataset.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wine8VeOgH_1"
      },
      "source": [
        "## 4. Observations/Interpretation\n",
        "\n",
        "Describe any pattern you see in the results. Relate your findings to what we discussed during lectures. Include data to justify your findings.\n",
        "\n",
        "\n",
        "\n",
        "  - When using logistic regression with only the first two columns, the validation accuracy (0.613) is actually slightly higher than the training accuracy (0.609). This is similar to the linear regression on the first two rows, where the validation MSE (46.41) is slightly lower than the training MSE (53.60). This is notable, because usually the model predicts the training set better than the validation set. \n",
        "\n",
        "\n",
        "  - We observe that the model performs poorly when we only use the first two columns of the data. This is because linear models are known to perform better when there are many features. If you have more features than data points you can perfectly model the training set with a linear model. We can say that for the case of just using the first two columns, our model is underfitting the data because we have high bias and low variance. \n",
        "     \n",
        "\n",
        "  - For both linear regression and logistic regression there is a decrease in the performance of the training set and increase in performance of the validation set when the training set size increases. This is expected, because for a given model complexity the larger the training set size the less likely it is for the model to overfit the data.\n",
        "\n",
        "    - For linear regression with only 1% of the data, the training MSE is close to zero which is desirable but the validation MSE is very high at 69.98.\n",
        "    - For Logistic regression with only 1% of the data, the training accuracy is very high at 0.941 but the validation accuracy is low at 0.750\n",
        "    \n",
        "- Using the above observations, we can say that when only using 1% of the data our model is too complex. We have high variance, which means we are overfitting the data.\n",
        "\n",
        "  When we increase the size of the data set (using all of the data), we see a substancial improvement:\n",
        "    - For logistic regression, the validation accuracy increases by 0.168, going from 0.750 to 0.918\n",
        "    - For linear regression, the validation MSE decreases by 59.62, from 69.98 to 10.36\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mY3BThjTgH_1"
      },
      "source": [
        "## 5. Reflection\n",
        "Include a sentence or two about:\n",
        "- what you liked or disliked,\n",
        "- found interesting, confusing, challangeing, motivating\n",
        "while working on this assignment.\n",
        "\n",
        "\n",
        "*My Reflection:*\n",
        "- I found the result of the validation score being better than the training score in the dataset of only the first 2 columns confusing. It may be because of the way that train_test_split has split the data for training and validation set.\n",
        "- I liked leaning how to actually use sklearn and see how the linear models are affected by changing the dataset.\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.15"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}